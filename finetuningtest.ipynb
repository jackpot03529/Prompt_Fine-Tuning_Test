{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be8OzWdgZkRM",
        "outputId": "0c2e2664-e9b7-4620-b416-9c377cd1e7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (0.40.0)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colossalai==0.2.7 in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (23.1)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (3.3.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (13.3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (8.1.3)\n",
            "Requirement already satisfied: fabric in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (3.1.0)\n",
            "Requirement already satisfied: contexttimer in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (0.3.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (1.11.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (1.13.0)\n",
            "Requirement already satisfied: invoke>=2.0 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai==0.2.7) (2.1.3)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai==0.2.7) (3.2.0)\n",
            "Requirement already satisfied: decorator>=5 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai==0.2.7) (5.1.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai==0.2.7) (3.3.1)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai==0.2.7) (2.5.24)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai==0.2.7) (1.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai==0.2.7) (6.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai==0.2.7) (20.23.1)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai==0.2.7) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai==0.2.7) (2.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->colossalai==0.2.7) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->colossalai==0.2.7) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->colossalai==0.2.7) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->colossalai==0.2.7) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->colossalai==0.2.7) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->colossalai==0.2.7) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->colossalai==0.2.7) (0.40.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->colossalai==0.2.7) (0.1.2)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai==0.2.7) (4.0.1)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai==0.2.7) (40.0.2)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai==0.2.7) (1.5.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7) (0.3.6)\n",
            "Requirement already satisfied: filelock<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7) (3.12.0)\n",
            "Requirement already satisfied: platformdirs<4,>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.2.7) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.2.7) (2.21)\n",
            "fatal: destination path 'KoChatGPT' already exists and is not an empty directory.\n",
            "mv: cannot stat 'KoChatGPT/data_kochatgpt': No such file or directory\n",
            "mv: cannot stat 'KoChatGPT/img': No such file or directory\n",
            "/content/KoChatGPT/colossalai_ChatGPT_230319\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/KoChatGPT/colossalai_ChatGPT_230319\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.20.1 in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (4.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (4.65.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: loralib in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (0.1.1)\n",
            "Requirement already satisfied: colossalai>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (0.2.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (1.13.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (0.0.113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (23.1)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (3.3.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (13.3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (8.1.3)\n",
            "Requirement already satisfied: fabric in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: contexttimer in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (0.3.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (0.15.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (0.3.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (3.8.4)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (1.4.48)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (0.5.8)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (1.10.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (8.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->chatgpt==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->chatgpt==0.1.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->chatgpt==0.1.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->chatgpt==0.1.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->chatgpt==0.1.0) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->chatgpt==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->chatgpt==0.1.0) (0.40.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain->chatgpt==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: invoke>=2.0 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: decorator>=5 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->chatgpt==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->chatgpt==0.1.0) (2022.7.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (2.5.24)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (20.23.1)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->colossalai>=0.2.4->chatgpt==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (4.0.1)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (40.0.2)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->chatgpt==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (0.3.6)\n",
            "Requirement already satisfied: platformdirs<4,>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (2.21)\n",
            "Building wheels for collected packages: chatgpt\n",
            "  Building wheel for chatgpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chatgpt: filename=chatgpt-0.1.0-py3-none-any.whl size=46647 sha256=590bb5b4ff417fdde04d15f4074fe7dc337c79ff4e8ae00004839fce1d3a4d79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s08rknjj/wheels/2b/0d/f8/b8f3ba4fd18f31a4096ee5bf83e4579cb54597f393eeae227c\n",
            "Successfully built chatgpt\n",
            "Installing collected packages: chatgpt\n",
            "  Attempting uninstall: chatgpt\n",
            "    Found existing installation: chatgpt 0.1.0\n",
            "    Uninstalling chatgpt-0.1.0:\n",
            "      Successfully uninstalled chatgpt-0.1.0\n",
            "Successfully installed chatgpt-0.1.0\n",
            "/content\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain==0.0.113 in /usr/local/lib/python3.10/dist-packages (0.0.113)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (1.4.48)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (3.8.4)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (0.5.8)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (1.22.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.113) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain==0.0.113) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.0\n",
        "## setup(1min)\n",
        "# for ColossalAI\n",
        "!pip install colossalai==0.2.7\n",
        "\n",
        "# setup data\n",
        "!git clone https://github.com/airobotlab/KoChatGPT\n",
        "!mv KoChatGPT/data_kochatgpt .\n",
        "!mv KoChatGPT/img .\n",
        "\n",
        "%cd KoChatGPT/colossalai_ChatGPT_230319/\n",
        "!pip install .\n",
        "%cd ../../\n",
        "\n",
        "# setup library\n",
        "!pip install openai\n",
        "!pip install langchain==0.0.113\n",
        "!pip install pandas>=1.4.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import torch\n",
        "!pip install transformers[torch]\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, pipeline\n",
        "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
        "from copy import deepcopy\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import copy\n",
        "import logging\n",
        "import json\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "def safe_save_model_for_hf_trainer(trainer: transformers.Trainer, output_dir: str):\n",
        "    \"\"\"Collects the state dict and dump to disk.\"\"\"\n",
        "    state_dict = trainer.model.state_dict()\n",
        "    if trainer.args.should_save:\n",
        "        cpu_state_dict = {key: value.cpu() for key, value in list(state_dict.items())}\n",
        "        del state_dict\n",
        "        trainer._save(output_dir, state_dict=cpu_state_dict)  # noqa"
      ],
      "metadata": {
        "id": "7UxD_I1vZ8-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391e1b7f-98c7-4b2e-fdfc-be3f1368c5f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.13.0)\n",
            "Requirement already satisfied: accelerate>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (0.40.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_path_1_SFT', type=str, default='/content/instruction_prompt_prepared.jsonl')\n",
        "parser.add_argument('--model_name', type=str, default='gpt2', choices=['gpt2', 'bloom', 'opt'])\n",
        "parser.add_argument('--max_epochs', type=int, default=2)\n",
        "parser.add_argument('--train_batch_size', type=int, default=8)\n",
        "parser.add_argument('--output_dir', type=str, default='./output_1_SFT')\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# for test\n",
        "args.model_name = 'skt/kogpt2-base-v2'  # SK GPT2, https://github.com/SKT-AI/KoGPT2\n",
        "# args.model_name = 'ajoublue-gpt2-base'  # ì•„ì£¼ëŒ€, https://github.com/HeegyuKim/language-model\n",
        "\n",
        "args.max_epochs = 2\n",
        "\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISGiPq1daH56",
        "outputId": "ad9c9158-3ad7-4cfc-fb8d-ab5163e32bf0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_path_1_SFT='/content/instruction_prompt_prepared.jsonl', model_name='skt/kogpt2-base-v2', max_epochs=2, train_batch_size=8, output_dir='./output_1_SFT')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test & load skt gpt2 kroean\n",
        "import torch\n",
        "!pip install transformers[torch]\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "                                                    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "                                                    pad_token='<pad>', mask_token='<mask>')\n",
        "print(tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\"))\n",
        "# ['â–ì•ˆë…•', 'í•˜', 'ì„¸', 'ìš”.', 'â–í•œêµ­ì–´', 'â–G', 'P', 'T', '-2', 'â–ì…', 'ë‹ˆë‹¤.', 'ğŸ˜¤', ':)', 'l^o']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj0w04ixah6q",
        "outputId": "faea0a43-264b-41bc-d956-a04c71d29f3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.13.0)\n",
            "Requirement already satisfied: accelerate>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (0.40.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['â–ì•ˆë…•', 'í•˜', 'ì„¸', 'ìš”.', 'â–í•œêµ­ì–´', 'â–G', 'P', 'T', '-2', 'â–ì…', 'ë‹ˆë‹¤.', 'ğŸ˜¤', ':)', 'l^o']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = 'ìš”ì¦˜ ì¢€ ìš°ìš¸í•œê±°ê°™ì•„'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                         max_length=128,\n",
        "                         repetition_penalty=2.0,\n",
        "                         pad_token_id=tokenizer.pad_token_id,\n",
        "                         eos_token_id=tokenizer.eos_token_id,\n",
        "                         bos_token_id=tokenizer.bos_token_id,\n",
        "                         use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)\n",
        "\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "generation_args = dict(\n",
        "    num_beams=4,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    eos_token_id=375, # \\n\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    early_stopping=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrvSTxoJnD9b",
        "outputId": "22755eef-96ac-424f-9330-3a17a0b79bed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ìš”ì¦˜ ì¢€ ìš°ìš¸í•œê±°ê°™ì•„ìš”.\n",
            "ë„¤. ë„¤. ì~ ì˜¤ëŠ˜ì€ ì–´ë–¤ ì£¼ì œë¡œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³¼ê¹Œ í•©ë‹ˆë‹¤.\n",
            "ì–´ë–»ê²Œ í•´ì•¼ ë ê¹Œìš”?\n",
            "ì ì´ì‹­ ëŒ€ë¶€í„° ì‹­ëŒ€ê¹Œì§€ ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì˜ ì‚¬ëŒë“¤ì´ ëª¨ì—¬ ìˆëŠ” ì»¤ë®¤ë‹ˆí‹° ê³µê°„ì…ë‹ˆë‹¤.\n",
            "ì´ê³³ì—ì„œ ê°€ì¥ ì£¼ëª©ë°›ëŠ” ê²ƒì€ ë°”ë¡œ ì–´ë¥´ì‹ ë“¤ì¸ë° ê·¸ì¤‘ì— í•œ ë¶„ì„ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
            "ë°”ë¡œ ì˜¤íŒ”ìœ¡êµ¬ ë‹˜ê»˜ì„œ ê³„ì…¨ëŠ”ë° ì €ëŠ” ì´ì œ ì¹ ì¹ ì˜¤ì‚¬ ë‹˜ì´ì‹œì£ .\n",
            "ì˜ˆ? ì˜ˆì˜ë„¤ìš”?\n",
            "ê·¸ëŸ°ë° ì œê°€ ì§€ê¸ˆ íŒ”ì‚¼ì¼ ì‚¬ì›”ë‹¬ì— ê²°í˜¼ì„ í–ˆì–´ìš”.\n",
            "ê·¸ë˜ì„œ ì•„ìœ  ê²°í˜¼í–ˆêµ¬ë‚˜.\n",
            "ê²°í˜¼í•˜ê³  ë‚˜ì„œ ì‚¼ ê°œì›” ë™ì•ˆ ì •ë§ í–‰ë³µí•˜ê²Œ ì‚´ì•˜\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data config\n",
        "IGNORE_INDEX = -100\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\"\n",
        "        \"ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ëª…ë ¹ì–´ì™€ ì¶”ê°€ì  ë§¥ë½ì„ ì œê³µí•˜ëŠ” ì…ë ¥ì´ ì§ì„ ì´ë£¨ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\\n\\n\"\n",
        "        \"Write a response that appropriately completes the request.\\nìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.\\n\\n\"\n",
        "        \"### Instruction(ëª…ë ¹ì–´):\\n{prompt}\\n\\n### Input(ì…ë ¥):\\n{input}\\n\\n### Response(ì‘ë‹µ):\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"Below is an instruction that describes a task.\\n\"\n",
        "        \"ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤.\\n\\n\"\n",
        "        \"Write a response that appropriately completes the request.\\nëª…ë ¹ì–´ì— ë”°ë¥¸ ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.\\n\\n\"\n",
        "        \"### Instruction(ëª…ë ¹ì–´):\\n{prompt}\\n\\n### Response(ì‘ë‹µ):\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "R83ek5_Uay1h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ëª¨ë¸ ì¤€ë¹„\n",
        "model = AutoModelForCausalLM.from_pretrained(args.model_name)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    args.model_name,\n",
        "    padding_side=\"right\",\n",
        "    model_max_length=512,\n",
        ")\n",
        "tokenizer.add_special_tokens(\n",
        "    {\n",
        "        \"eos_token\": DEFAULT_EOS_TOKEN,\n",
        "        \"bos_token\": DEFAULT_BOS_TOKEN,\n",
        "        \"unk_token\": DEFAULT_UNK_TOKEN,\n",
        "    }\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Z-uJfCa1YK",
        "outputId": "77c55896-86a2-4f11-d0c6-0ff21fa8f226"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## prepare data\n",
        "from typing import Optional, Dict, Sequence\n",
        "\n",
        "class SFT_dataset(Dataset):\n",
        "    '''SFT dataset by wygo'''\n",
        "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
        "        super(SFT_dataset, self).__init__()\n",
        "        logging.warning(\"Loading data...\")\n",
        "\n",
        "        ## format\n",
        "        pattern_instruction = 'prompt'  # instruction\n",
        "        pattern_input = 'input'# ë‚´ ë°ì´í„°ì—” inputì´ ì—†ë‹¤\n",
        "        pattern_output = 'completion'  # output\n",
        "\n",
        "        ############################################################\n",
        "        ## load dataset\n",
        "        # ë‚´ ë°ì´í„°ì…‹ì—” inputì´ ì—†ë‹¤\n",
        "#         data_path_1_SFT = 'data_kochatgpt/korean_chatgpt_1_SFT.jsonl'\n",
        "        list_data_dict = []\n",
        "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
        "          for line in json_file:\n",
        "            list_data_dict.append(json.loads(line))\n",
        "            if verbose:\n",
        "                print('## data check ##')\n",
        "                print((list_data_dict[0]))\n",
        "        # {'prompt': 'ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?',\n",
        "        #  'completion': \"'ì €ëŠ” ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë©°, ì§ì ‘ì ìœ¼ë¡œ ì‹í’ˆì— ê´€í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆê³ ê¸°ìš© ê³ ê¸°ëŠ” í•œìš°, ì‡ ê³ ê¸°, ë¼ì§€ê³ ê¸° ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ê³ ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ í•œìš°ëŠ” ëŒ€í‘œì ì¸ ê³ ê¸‰ ìœ¡ë¥˜ë¡œ ì•Œë ¤ì ¸ ìˆê¸° ë•Œë¬¸ì—, í•œìš°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë„ ë§ìŠµë‹ˆë‹¤. ì•ŒëŸ¬ì§€ë‚˜ ê°œë³„ ê±´ê°• ìƒíƒœì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì¶©ë¶„í•œ ì •ë³´ ìˆ˜ì§‘ í›„ì— ì„ íƒí•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\",\n",
        "        #  'tokens': 193}\n",
        "\n",
        "        ############################################################\n",
        "        ## ë°ì´í„°ì…‹ ë§Œë“¤ê¸°, sourceì™€ target\n",
        "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]  # í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "        # ì…ë ¥\n",
        "        sources = []\n",
        "        for example in list_data_dict:\n",
        "            if example.get(pattern_input, \"\") != \"\":\n",
        "                tmp = prompt_input.format_map(example)\n",
        "            else:\n",
        "                tmp = prompt_no_input.format_map(example)\n",
        "            sources.append(tmp)\n",
        "\n",
        "        # ì¶œë ¥\n",
        "        targets = []\n",
        "        for example in list_data_dict:\n",
        "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
        "\n",
        "        if verbose:\n",
        "            idx = 0\n",
        "            print((sources[idx]))\n",
        "            print((targets[idx]))\n",
        "            print(\"Tokenizing inputs... This may take some time...\")\n",
        "\n",
        "        ############################################################\n",
        "        # data_dict = preprocess(sources, targets, tokenizer)  # https://github.com/Beomi/KoAlpaca/blob/04704348d58b8b1c2e2638d6437a04b4e8ba1823/train.py#L124\n",
        "        examples = [s + t for s, t in zip(sources, targets)]\n",
        "\n",
        "        # source data tokenized\n",
        "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # sourceë§Œ\n",
        "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
        "\n",
        "\n",
        "        ## ì…ë ¥ì€ source, ì¶œë ¥ì€ source+target ì´ì§€ë§Œ í•™ìŠµì€ target ë¶€ë¶„ë§Œ\n",
        "        input_ids = examples_tokenized[\"input_ids\"]\n",
        "        labels = copy.deepcopy(input_ids)\n",
        "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
        "            label[:source_len] = IGNORE_INDEX  # source ë¶€ë¶„ì€ -100ìœ¼ë¡œ ì±„ìš´ë‹¤\n",
        "\n",
        "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
        "\n",
        "        self.input_ids = data_dict[\"input_ids\"]\n",
        "        self.labels = data_dict[\"labels\"]\n",
        "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
        "\n",
        "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
        "        \"\"\"Tokenize a list of strings.\"\"\"\n",
        "        tokenized_list = [\n",
        "            tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"longest\",\n",
        "                max_length=tokenizer.model_max_length,\n",
        "                truncation=True,\n",
        "            )\n",
        "            for text in strings\n",
        "        ]\n",
        "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
        "        input_ids_lens = labels_lens = [\n",
        "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
        "        ]\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            input_ids_lens=input_ids_lens,\n",
        "            labels_lens=labels_lens,\n",
        "        )\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
        "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForSupervisedDataset(object):\n",
        "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
        "\n",
        "    tokenizer: transformers.PreTrainedTokenizer\n",
        "\n",
        "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
        "        )\n",
        "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = SFT_dataset(data_path_1_SFT=args.data_path_1_SFT, tokenizer=tokenizer)\n",
        "eval_dataset  = None  # evalì€ ì•ˆí•¨\n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx16YX4wa1_r",
        "outputId": "29e45159-4f03-4c8d-8685-d3a25f10dfde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Loading data...\n",
            "WARNING:root:Loading data done!!: 159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## í•™ìŠµ (10min)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./test\", #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=50, # number of training epochs\n",
        "    per_device_train_batch_size=4, # batch size for training\n",
        "    per_device_eval_batch_size=4,  # batch size for evaluation\n",
        "    eval_steps = 3, # Number of update steps between two evaluations.\n",
        "    save_steps=500, # after # steps model is saved\n",
        "    warmup_steps=5,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    )\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_state()\n",
        "safe_save_model_for_hf_trainer(trainer=trainer, output_dir=args.output_dir)"
      ],
      "metadata": {
        "id": "cU1WpoWfa_wi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "a913dffc-805e-419b-e86f-9078021e68ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 00:17, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
        "generator = pipeline('text-generation', model=args.output_dir, tokenizer=tokenizer)\n",
        "# generator = pipeline('text-generation', model=model.cpu(), tokenizer=tokenizer, config={'max_length':800})\n",
        "\n",
        "generation_args = dict(\n",
        "    num_beams=4,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    # eos_token_id=375, # \\n\n",
        "    max_new_tokens=4096,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        ")\n",
        "\n",
        "list_prompt = ['ìš”ì¦˜ ì¢€ ìš°ìš¸í•œê±° ê°™ì•„. ì´ë•Œ ì½ì„ ë§Œí•œ ì±… 5ê¶Œ ì¶”ì²œí•´ì¤˜']\n",
        "list_prompt = [PROMPT_DICT['prompt_no_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
        "\n",
        "list_result = generator(list_prompt, **generation_args)\n",
        "for prompt, result in zip(list_prompt, list_result):\n",
        "    print(('#'*70))\n",
        "    print(('completion: %s'%(result[0]['generated_text'])))"
      ],
      "metadata": {
        "id": "LFYCZ7utbOxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a6e5db-84c2-4130-d97b-5eb1ef0a3d17"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################################################################\n",
            "completion: Below is an instruction that describes a task.\n",
            "ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤.\n",
            "\n",
            "Write a response that appropriately completes the request.\n",
            "ëª…ë ¹ì–´ì— ë”°ë¥¸ ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.\n",
            "\n",
            "### Instruction(ëª…ë ¹ì–´):\n",
            "ìš”ì¦˜ ì¢€ ìš°ìš¸í•œê±° ê°™ì•„. ì´ë•Œ ì½ì„ ë§Œí•œ ì±… 5ê¶Œ ì¶”ì²œí•´ì¤˜\n",
            "\n",
            "### Response(ì‘ë‹µ): ìš°ìš¸í•œ ê¸°ë¶„ì„ ê°€ë¼ì•‰í ìˆ˜ ìˆëŠ” ëª‡ ê°€ì§€ ì±…ì„ ì¶”ì²œí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤:\n",
            "\n",
            "1. \"ì•ˆë„¤ì˜ ì¼ê¸°\" (ì¡°ì§€ ì˜¤ì›° ì €)\n",
            "- ì´ ì±…ì€ ì•ˆë„¤ì˜ ì¼ê¸°ë¥¼ í†µí•´ ë…ìë“¤ì—ê²Œ ìœ„ë¡œì™€ ìœ„ë¡œë¥¼ ì „í•´ì¤ë‹ˆë‹¤.\n",
            "\n",
            "2. \"ë§ˆìŒì„ ì¹˜ìœ í•˜ëŠ” ë²•\" (ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ ì €)\n",
            "- \"ì´ ì±…ì€ ë§ˆìŒì„ ì¹˜ìœ í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤ë‹ˆë‹¤. ë…ìë“¤ì—ê²Œ ë§ˆìŒì˜ ìƒì²˜ë¥¼ ì¹˜ìœ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ChDOMdPQztAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}